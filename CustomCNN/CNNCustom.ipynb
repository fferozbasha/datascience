{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dummy data set with size as 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.rand(30,30)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the shape as 28, 28, 1 denoting it as grayscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(data.shape[0],data.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 1)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Filters of 3*3 size to use for convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data=None, filterArray=None, stride=1, process_name='conv', padding_size=0, pool_size=(0,0)):\n",
    "    \"\"\"\n",
    "    \n",
    "    Method can be used to do \n",
    "        convolution based on filter provided\n",
    "        Pad the data as required\n",
    "        max pooling\n",
    "        average pooling\n",
    "    \"\"\"\n",
    "    \n",
    "    if padding_size>0:\n",
    "        print(f\"Adding padding\")\n",
    "        data = addPadding(data, padding_size=padding_size)\n",
    "     \n",
    "    max_rowIdx = data.shape[0]\n",
    "    max_colIdx = data.shape[1]\n",
    "        \n",
    "    if process_name=='conv':\n",
    "        filter_row_size = filterArray.shape[0]\n",
    "        filter_col_size = filterArray.shape[1]\n",
    "        filter_shape = filterArray.shape\n",
    "    elif process_name == 'max_pooling' or process_name == 'avg_pooling':\n",
    "        filter_row_size = pool_size[0]\n",
    "        filter_col_size = pool_size[1]\n",
    "\n",
    "    expected_outcome_row_size = (data.shape[0] - filter_row_size)/stride + 1\n",
    "    expected_outcome_col_size = (data.shape[1] - filter_col_size)/stride + 1\n",
    "    \n",
    "    if expected_outcome_row_size - np.fix(expected_outcome_row_size)>0.5:\n",
    "        expected_outcome_row_size = np.ceil(expected_outcome_row_size).astype(int)\n",
    "    else:\n",
    "        expected_outcome_row_size = np.floor(expected_outcome_row_size).astype(int)\n",
    "        \n",
    "    if expected_outcome_col_size - np.fix(expected_outcome_col_size) > 0.5:\n",
    "        expected_outcome_col_size = np.ceil(expected_outcome_col_size).astype(int)\n",
    "    else:\n",
    "        expected_outcome_col_size = np.floor(expected_outcome_col_size).astype(int)\n",
    "\n",
    "    convoluted_values = []\n",
    "    \n",
    "    print(f\"Input data shape = {data.shape}\")\n",
    "    if process_name == 'conv':\n",
    "        print(f\"Filter size = {filter_shape}\")\n",
    "    else:\n",
    "        print(f\"Pool size = {pool_size}\")\n",
    "    print(f\"Stride = {stride}\")\n",
    "    print(f\"Expected output size = ({expected_outcome_row_size}, {expected_outcome_col_size})\")\n",
    "    \n",
    "    #Iterating for every row with step as the Stride\n",
    "    for rowIdx in np.arange(0, data.shape[0], stride):\n",
    "                \n",
    "        conv_area_row_min = rowIdx\n",
    "        conv_area_row_max = rowIdx + (filter_row_size)\n",
    "\n",
    "        if conv_area_row_max <= max_rowIdx:        \n",
    "            #Iterating for every col with ste as the Stride\n",
    "            for colIdx in np.arange(0, data.shape[1], stride):\n",
    "                \n",
    "                conv_area_col_min = colIdx\n",
    "                conv_area_col_max = colIdx + (filter_col_size)\n",
    "\n",
    "                if conv_area_col_max <= max_colIdx:\n",
    "\n",
    "                    curr_conv_area = data[conv_area_row_min:conv_area_row_max, conv_area_col_min:conv_area_col_max]\n",
    "                    if process_name=='conv':\n",
    "                        convoluted_value = np.sum(np.multiply(curr_conv_area, filterArray))\n",
    "                    elif process_name=='max_pooling':\n",
    "                        convoluted_value = np.max(curr_conv_area)\n",
    "                    elif process_name=='avg_pooling':\n",
    "                        convoluted_value = np.average(curr_conv_area)\n",
    "                    else:\n",
    "                        print(\"Unsupported operation\")\n",
    "                        return null\n",
    "                    \n",
    "                    convoluted_values.append(convoluted_value)\n",
    "                    \n",
    "    convoluted_values = np.array(convoluted_values).reshape(expected_outcome_row_size, expected_outcome_col_size)\n",
    "    return convoluted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(data, padding_size=1):\n",
    "    \n",
    "    print(f\"Input data shape {data.shape}\")\n",
    "    actual_data_row_size = data.shape[0]\n",
    "    actual_data_col_size = data.shape[1]\n",
    "    \n",
    "    padded_data = np.zeros((actual_data_row_size + 2*padding_size, actual_data_col_size + 2*padding_size))\n",
    "    \n",
    "    for rowIdx in range(padded_data.shape[0]):\n",
    "        if rowIdx >=padding_size and rowIdx<=actual_data_row_size:\n",
    "            for colIdx in range(padded_data.shape[1]):\n",
    "                if colIdx >= padding_size and colIdx<=actual_data_col_size:\n",
    "                    padded_data[rowIdx][colIdx] = data[rowIdx-padding_size][colIdx-padding_size]\n",
    "                    \n",
    "    padded_data = padded_data.reshape(padded_data.shape[0], padded_data.shape[1], 1)\n",
    "    print(f\"Padded data array shape {padded_data.shape}\")\n",
    "    return padded_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing convolution with 3*3 filter, stride=1 without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape = (30, 30, 1)\n",
      "Filter size = (3, 3)\n",
      "Stride = 1\n",
      "Expected output size = (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = process(data=data, filterArray=filter_1, stride=1, process_name='conv', padding_size=0)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing convolution with 3*3 filter, stride=2 and with Padding size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding padding\n",
      "Input data shape (30, 30, 1)\n",
      "Padded data array shape (32, 32, 1)\n",
      "Input data shape = (32, 32, 1)\n",
      "Filter size = (3, 3)\n",
      "Stride = 2\n",
      "Expected output size = (15, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = process(data=data, filterArray=filter_1, stride=2, process_name='conv', padding_size=1)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing convolution with 3*3 filter, stride=2 and Padding size =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding padding\n",
      "Input data shape (30, 30, 1)\n",
      "Padded data array shape (34, 34, 1)\n",
      "Input data shape = (34, 34, 1)\n",
      "Filter size = (3, 3)\n",
      "Stride = 2\n",
      "Expected output size = (16, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = process(data=data, filterArray=filter_1, stride=2, process_name='conv', padding_size=2)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing max pooling with stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape = (30, 30, 1)\n",
      "Pool size = (2, 2)\n",
      "Stride = 2\n",
      "Expected output size = (15, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = process(data=data, pool_size=(2,2), stride=2, process_name='max_pooling')\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing average pooling with stride=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape = (30, 30, 1)\n",
      "Pool size = (2, 2)\n",
      "Stride = 1\n",
      "Expected output size = (29, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = process(data=data,  stride=1, pool_size=(2,2), process_name='avg_pooling')\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
